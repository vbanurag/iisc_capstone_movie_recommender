{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of users, items and ratings involved in the loaded movielens dataset:  ['943 users', '1682 items', '100000 ratings']\n"
     ]
    }
   ],
   "source": [
    "overall_stats = pd.read_csv('./../data/ml-100k/u.info', header=None)\n",
    "print(\"Details of users, items and ratings involved in the loaded movielens dataset: \",list(overall_stats[0]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id  movie id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116\n",
       "3      244        51       2  880606923\n",
       "4      166       346       1  886397596"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_coulmns = ['user id','movie id','rating','timestamp']\n",
    "ratings_dataset = pd.read_csv('./../data/ml-100k/u.data', sep='\\t',header=None,names=movie_coulmns)\n",
    "ratings_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user id  movie id  rating  timestamp\n",
       "1        1         5       874965758    1\n",
       "606      91        5       880926610    1\n",
       "         144       4       880924664    1\n",
       "         138       3       880927923    1\n",
       "         135       5       880926245    1\n",
       "                                       ..\n",
       "311      747       3       884364502    1\n",
       "         739       4       884365823    1\n",
       "         735       4       884366637    1\n",
       "         732       4       884365617    1\n",
       "943      1330      3       888692465    1\n",
       "Name: count, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDb URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mat%27+i+syn+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?B%2E+Monkey+(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Sliding+Doors+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?You%20So%20Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Schrei%20aus%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie id                                movie title release date  \\\n",
       "0            1                           Toy Story (1995)  01-Jan-1995   \n",
       "1            2                           GoldenEye (1995)  01-Jan-1995   \n",
       "2            3                          Four Rooms (1995)  01-Jan-1995   \n",
       "3            4                          Get Shorty (1995)  01-Jan-1995   \n",
       "4            5                             Copycat (1995)  01-Jan-1995   \n",
       "...        ...                                        ...          ...   \n",
       "1677      1678                          Mat' i syn (1997)  06-Feb-1998   \n",
       "1678      1679                           B. Monkey (1998)  06-Feb-1998   \n",
       "1679      1680                       Sliding Doors (1998)  01-Jan-1998   \n",
       "1680      1681                        You So Crazy (1994)  01-Jan-1994   \n",
       "1681      1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996   \n",
       "\n",
       "      video release date                                           IMDb URL  \\\n",
       "0                    NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                    NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                    NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                    NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                    NaN  http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
       "...                  ...                                                ...   \n",
       "1677                 NaN  http://us.imdb.com/M/title-exact?Mat%27+i+syn+...   \n",
       "1678                 NaN  http://us.imdb.com/M/title-exact?B%2E+Monkey+(...   \n",
       "1679                 NaN      http://us.imdb.com/Title?Sliding+Doors+(1998)   \n",
       "1680                 NaN  http://us.imdb.com/M/title-exact?You%20So%20Cr...   \n",
       "1681                 NaN  http://us.imdb.com/M/title-exact?Schrei%20aus%...   \n",
       "\n",
       "      unknown  Action  Adventure  Animation  Children  ...  Fantasy  \\\n",
       "0           0       0          0          1         1  ...        0   \n",
       "1           0       1          1          0         0  ...        0   \n",
       "2           0       0          0          0         0  ...        0   \n",
       "3           0       1          0          0         0  ...        0   \n",
       "4           0       0          0          0         0  ...        0   \n",
       "...       ...     ...        ...        ...       ...  ...      ...   \n",
       "1677        0       0          0          0         0  ...        0   \n",
       "1678        0       0          0          0         0  ...        0   \n",
       "1679        0       0          0          0         0  ...        0   \n",
       "1680        0       0          0          0         0  ...        0   \n",
       "1681        0       0          0          0         0  ...        0   \n",
       "\n",
       "      Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
       "0             0       0        0        0        0       0         0    0   \n",
       "1             0       0        0        0        0       0         1    0   \n",
       "2             0       0        0        0        0       0         1    0   \n",
       "3             0       0        0        0        0       0         0    0   \n",
       "4             0       0        0        0        0       0         1    0   \n",
       "...         ...     ...      ...      ...      ...     ...       ...  ...   \n",
       "1677          0       0        0        0        0       0         0    0   \n",
       "1678          0       0        0        0        1       0         1    0   \n",
       "1679          0       0        0        0        1       0         0    0   \n",
       "1680          0       0        0        0        0       0         0    0   \n",
       "1681          0       0        0        0        0       0         0    0   \n",
       "\n",
       "      Western  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "1677        0  \n",
       "1678        0  \n",
       "1679        0  \n",
       "1680        0  \n",
       "1681        0  \n",
       "\n",
       "[1682 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 'movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western'\n",
    "movies_data_columns = d.split(' | ')\n",
    "movies_data_columns\n",
    "items_dataset = pd.read_csv(\"./../data/ml-100k/u.item\", sep='|',header=None,names=movies_data_columns,encoding='latin-1')\n",
    "items_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>movie title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id        movie title\n",
       "0         1   Toy Story (1995)\n",
       "1         2   GoldenEye (1995)\n",
       "2         3  Four Rooms (1995)\n",
       "3         4  Get Shorty (1995)\n",
       "4         5     Copycat (1995)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movie_dataset = items_dataset[['movie id','movie title']]\n",
    "movie_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 1682)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items_dataset.groupby(by=movies_data_columns[1:])),len(items_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged dataset for further observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id  movie id  rating  timestamp                 movie title\n",
       "0      196       242       3  881250949                Kolya (1996)\n",
       "1      186       302       3  891717742    L.A. Confidential (1997)\n",
       "2       22       377       1  878887116         Heavyweights (1994)\n",
       "3      244        51       2  880606923  Legends of the Fall (1994)\n",
       "4      166       346       1  886397596         Jackie Brown (1997)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = pd.merge(ratings_dataset, movie_dataset, how='inner', on='movie id')\n",
    "merged_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62716</th>\n",
       "      <td>894</td>\n",
       "      <td>246</td>\n",
       "      <td>4</td>\n",
       "      <td>882404137</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90596</th>\n",
       "      <td>894</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>879896041</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user id  movie id  rating  timestamp         movie title\n",
       "62716      894       246       4  882404137  Chasing Amy (1997)\n",
       "90596      894       268       3  879896041  Chasing Amy (1997)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset[(merged_dataset['movie title'] == 'Chasing Amy (1997)') & (merged_dataset['user id'] == 894)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101 Dalmatians (1996)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20,000 Leagues Under the Sea (1954)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2001: A Space Odyssey (1968)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Abyss, The (1989)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id                          movie title  rating\n",
       "0        1                101 Dalmatians (1996)     2.0\n",
       "1        1                  12 Angry Men (1957)     5.0\n",
       "2        1  20,000 Leagues Under the Sea (1954)     3.0\n",
       "3        1         2001: A Space Odyssey (1968)     4.0\n",
       "4        1                    Abyss, The (1989)     3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_dataset = merged_dataset.groupby(by=['user id','movie title'], as_index=False).agg({\"rating\":\"mean\"})\n",
    "\n",
    "refined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user id  movie title                                 rating\n",
       "1        101 Dalmatians (1996)                       2.0       1\n",
       "606      Casablanca (1942)                           5.0       1\n",
       "         Devil's Advocate, The (1997)                4.0       1\n",
       "         Desperado (1995)                            4.0       1\n",
       "         Dead Poets Society (1989)                   4.0       1\n",
       "                                                              ..\n",
       "311      Star Trek III: The Search for Spock (1984)  5.0       1\n",
       "         Stand by Me (1986)                          4.0       1\n",
       "         Speed (1994)                                5.0       1\n",
       "         Speechless (1994)                           3.0       1\n",
       "943      Young Guns II (1990)                        3.0       1\n",
       "Name: count, Length: 99693, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding users and movie titles is crucial for several important reasons:\n",
    "\n",
    "- Neural Network Requirements:\n",
    "\n",
    "  - DNNs require numerical inputs\n",
    "  - Input features must be in a continuous sequence (no gaps)\n",
    "  - Missing values can cause training issues\n",
    "\n",
    "\n",
    "- Memory Efficiency:\n",
    "\n",
    "  - Converts potentially long string IDs into compact integer indices\n",
    "  - Reduces memory usage during training\n",
    "  - Speeds up computations\n",
    "\n",
    "\n",
    "- Handling Cold Start:\n",
    "\n",
    "  - Enables handling of new users and movies not seen during training\n",
    "  - Provides a systematic way to assign new IDs to unknown entities\n",
    "\n",
    "\n",
    "- Model Performance:\n",
    "\n",
    "  - Consistent encoding helps prevent data leakage\n",
    "  - Maintains the relationship between users and movies\n",
    "  - Enables proper embedding layer initialization\n",
    "\n",
    "\n",
    "- Training Stability:\n",
    "\n",
    "  - Sequential IDs ensure consistent embedding lookups\n",
    "  - Prevents sparse or skipped indices that could affect model convergence\n",
    "  - Makes batch processing more efficient\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_enc = LabelEncoder()\n",
    "refined_dataset['user'] = user_enc.fit_transform(refined_dataset['user id'].values)\n",
    "n_users = refined_dataset['user'].nunique()\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_enc = LabelEncoder()\n",
    "refined_dataset['movie'] = movie_enc.fit_transform(refined_dataset['movie title'].values)\n",
    "n_movies = refined_dataset['movie'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1664, 1.0, 5.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_dataset['rating'] = refined_dataset['rating'].values.astype(np.float32)\n",
    "min_rating = min(refined_dataset['rating'])\n",
    "max_rating = max(refined_dataset['rating'])\n",
    "n_users, n_movies, min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>rating</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101 Dalmatians (1996)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20,000 Leagues Under the Sea (1954)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2001: A Space Odyssey (1968)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Abyss, The (1989)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id                          movie title  rating  user  movie\n",
       "0        1                101 Dalmatians (1996)     2.0     0      2\n",
       "1        1                  12 Angry Men (1957)     5.0     0      3\n",
       "2        1  20,000 Leagues Under the Sea (1954)     3.0     0      6\n",
       "3        1         2001: A Space Odyssey (1968)     4.0     0      7\n",
       "4        1                    Abyss, The (1989)     3.0     0     16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into Test and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89723, 2), (9970, 2), (89723,), (9970,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = refined_dataset[['user', 'movie']].values\n",
    "Y = refined_dataset['rating'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=50)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89723,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 150\n",
    "\n",
    "\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 180, 1152],\n",
       "        [ 487,  389],\n",
       "        [ 177,  302],\n",
       "        ...,\n",
       "        [ 431, 1588],\n",
       "        [ 232,  399],\n",
       "        [ 138,  612]]),\n",
       " [array([180, 487, 177, ..., 431, 232, 138]),\n",
       "  array([1152,  389,  302, ..., 1588,  399,  612])],\n",
       " (89723,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train_array, X_train_array[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = (Y_train - min_rating)/(max_rating - min_rating)\n",
    "Y_test = (Y_test - min_rating)/(max_rating - min_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax deep neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # User input and embedding\n",
    "user = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_input')\n",
    "\n",
    "u = tf.keras.layers.Embedding(\n",
    "    input_dim=n_users,\n",
    "    output_dim=n_factors,\n",
    "    embeddings_initializer=tf.keras.initializers.HeNormal(),\n",
    "    embeddings_regularizer=tf.keras.regularizers.l2(1e-6)\n",
    ")(user)\n",
    "u = tf.keras.layers.Reshape((n_factors,))(u)\n",
    "\n",
    "# Movie input and embedding\n",
    "movie = tf.keras.layers.Input(shape=(1,), dtype='int32')  # Added dtype here too\n",
    "\n",
    "m = keras.layers.Embedding(\n",
    "    input_dim=n_movies,\n",
    "    output_dim=n_factors,\n",
    "    embeddings_initializer='he_normal',\n",
    "    embeddings_regularizer=tf.keras.regularizers.l2(1e-6)\n",
    ")(movie)\n",
    "m = tf.keras.layers.Reshape((n_factors,))(m) \n",
    "\n",
    "## Rest of the model remains the same\n",
    "x = tf.keras.layers.Concatenate()([u,m])\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(32, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(16, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(9)(x)\n",
    "x = tf.keras.layers.Activation(activation='softmax')(x)  # Fixed: lowercase 'softmax'\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[user,movie], outputs=x)\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"Adagrad\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">141,450</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">249,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,632</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)    │    \u001b[38;5;34m141,450\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)    │    \u001b[38;5;34m249,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m9,632\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │        \u001b[38;5;34m153\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,363</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m401,363\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,363</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m401,363\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'keras_tensor_2']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1100 - loss: 2.1183\n",
      "Epoch 1: val_loss improved from inf to 1.94969, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1098 - loss: 2.1172 - val_accuracy: 0.0670 - val_loss: 1.9497 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m680/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0709 - loss: 1.9013\n",
      "Epoch 2: val_loss improved from 1.94969 to 1.74194, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0708 - loss: 1.8997 - val_accuracy: 0.0617 - val_loss: 1.7419 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m699/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0677 - loss: 1.6894\n",
      "Epoch 3: val_loss improved from 1.74194 to 1.51844, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0677 - loss: 1.6891 - val_accuracy: 0.0617 - val_loss: 1.5184 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0647 - loss: 1.4661\n",
      "Epoch 4: val_loss improved from 1.51844 to 1.29224, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0647 - loss: 1.4659 - val_accuracy: 0.0617 - val_loss: 1.2922 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0616 - loss: 1.2475\n",
      "Epoch 5: val_loss improved from 1.29224 to 1.09208, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0616 - loss: 1.2474 - val_accuracy: 0.0617 - val_loss: 1.0921 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m697/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 1.0599\n",
      "Epoch 6: val_loss improved from 1.09208 to 0.93461, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 1.0596 - val_accuracy: 0.0617 - val_loss: 0.9346 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m688/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0622 - loss: 0.9201\n",
      "Epoch 7: val_loss improved from 0.93461 to 0.82013, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0622 - loss: 0.9195 - val_accuracy: 0.0617 - val_loss: 0.8201 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m687/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0613 - loss: 0.8174\n",
      "Epoch 8: val_loss improved from 0.82013 to 0.74067, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0613 - loss: 0.8170 - val_accuracy: 0.0617 - val_loss: 0.7407 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m684/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.7458\n",
      "Epoch 9: val_loss improved from 0.74067 to 0.68631, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.7455 - val_accuracy: 0.0617 - val_loss: 0.6863 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m687/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0602 - loss: 0.6972\n",
      "Epoch 10: val_loss improved from 0.68631 to 0.64871, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0602 - loss: 0.6970 - val_accuracy: 0.0617 - val_loss: 0.6487 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m687/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.6631\n",
      "Epoch 11: val_loss improved from 0.64871 to 0.62198, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0606 - loss: 0.6630 - val_accuracy: 0.0617 - val_loss: 0.6220 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.6381\n",
      "Epoch 12: val_loss improved from 0.62198 to 0.60237, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.6381 - val_accuracy: 0.0617 - val_loss: 0.6024 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.6236\n",
      "Epoch 13: val_loss improved from 0.60237 to 0.58745, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.6235 - val_accuracy: 0.0617 - val_loss: 0.5875 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m695/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.6067\n",
      "Epoch 14: val_loss improved from 0.58745 to 0.57580, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.6067 - val_accuracy: 0.0617 - val_loss: 0.5758 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m681/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0608 - loss: 0.5976\n",
      "Epoch 15: val_loss improved from 0.57580 to 0.56646, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0608 - loss: 0.5975 - val_accuracy: 0.0617 - val_loss: 0.5665 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m685/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 0.5859\n",
      "Epoch 16: val_loss improved from 0.56646 to 0.55881, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.5858 - val_accuracy: 0.0617 - val_loss: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m694/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5752\n",
      "Epoch 17: val_loss improved from 0.55881 to 0.55243, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5752 - val_accuracy: 0.0617 - val_loss: 0.5524 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m695/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0616 - loss: 0.5715\n",
      "Epoch 18: val_loss improved from 0.55243 to 0.54704, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0616 - loss: 0.5715 - val_accuracy: 0.0617 - val_loss: 0.5470 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m689/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.5664\n",
      "Epoch 19: val_loss improved from 0.54704 to 0.54241, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.5664 - val_accuracy: 0.0617 - val_loss: 0.5424 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m681/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5624\n",
      "Epoch 20: val_loss improved from 0.54241 to 0.53839, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5623 - val_accuracy: 0.0617 - val_loss: 0.5384 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m679/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.5613\n",
      "Epoch 21: val_loss improved from 0.53839 to 0.53485, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0605 - loss: 0.5612 - val_accuracy: 0.0617 - val_loss: 0.5349 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m696/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0597 - loss: 0.5540\n",
      "Epoch 22: val_loss improved from 0.53485 to 0.53169, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0597 - loss: 0.5540 - val_accuracy: 0.0617 - val_loss: 0.5317 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m681/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0610 - loss: 0.5526\n",
      "Epoch 23: val_loss improved from 0.53169 to 0.52885, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0610 - loss: 0.5525 - val_accuracy: 0.0617 - val_loss: 0.5288 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m698/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5479\n",
      "Epoch 24: val_loss improved from 0.52885 to 0.52628, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5479 - val_accuracy: 0.0617 - val_loss: 0.5263 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m690/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0595 - loss: 0.5434\n",
      "Epoch 25: val_loss improved from 0.52628 to 0.52395, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0595 - loss: 0.5434 - val_accuracy: 0.0617 - val_loss: 0.5240 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m694/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5427\n",
      "Epoch 26: val_loss improved from 0.52395 to 0.52180, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5427 - val_accuracy: 0.0617 - val_loss: 0.5218 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m686/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0611 - loss: 0.5402\n",
      "Epoch 27: val_loss improved from 0.52180 to 0.51980, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0611 - loss: 0.5402 - val_accuracy: 0.0617 - val_loss: 0.5198 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m699/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0616 - loss: 0.5396\n",
      "Epoch 28: val_loss improved from 0.51980 to 0.51794, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0616 - loss: 0.5396 - val_accuracy: 0.0617 - val_loss: 0.5179 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5344\n",
      "Epoch 29: val_loss improved from 0.51794 to 0.51619, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5344 - val_accuracy: 0.0617 - val_loss: 0.5162 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m699/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5366\n",
      "Epoch 30: val_loss improved from 0.51619 to 0.51453, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5366 - val_accuracy: 0.0617 - val_loss: 0.5145 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m688/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0621 - loss: 0.5351\n",
      "Epoch 31: val_loss improved from 0.51453 to 0.51295, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0621 - loss: 0.5350 - val_accuracy: 0.0617 - val_loss: 0.5130 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m684/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5337\n",
      "Epoch 32: val_loss improved from 0.51295 to 0.51146, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5336 - val_accuracy: 0.0617 - val_loss: 0.5115 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m681/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0617 - loss: 0.5261\n",
      "Epoch 33: val_loss improved from 0.51146 to 0.51001, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0617 - loss: 0.5262 - val_accuracy: 0.0617 - val_loss: 0.5100 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m688/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0600 - loss: 0.5279\n",
      "Epoch 34: val_loss improved from 0.51001 to 0.50862, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0600 - loss: 0.5279 - val_accuracy: 0.0617 - val_loss: 0.5086 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m688/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5248\n",
      "Epoch 35: val_loss improved from 0.50862 to 0.50729, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5248 - val_accuracy: 0.0617 - val_loss: 0.5073 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m690/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5238\n",
      "Epoch 36: val_loss improved from 0.50729 to 0.50599, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0614 - loss: 0.5238 - val_accuracy: 0.0617 - val_loss: 0.5060 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m680/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0609 - loss: 0.5254\n",
      "Epoch 37: val_loss improved from 0.50599 to 0.50471, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0610 - loss: 0.5253 - val_accuracy: 0.0617 - val_loss: 0.5047 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m685/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0610 - loss: 0.5246\n",
      "Epoch 38: val_loss improved from 0.50471 to 0.50348, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0610 - loss: 0.5245 - val_accuracy: 0.0617 - val_loss: 0.5035 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5191\n",
      "Epoch 39: val_loss improved from 0.50348 to 0.50226, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5191 - val_accuracy: 0.0617 - val_loss: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0632 - loss: 0.5195\n",
      "Epoch 40: val_loss improved from 0.50226 to 0.50106, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0632 - loss: 0.5195 - val_accuracy: 0.0617 - val_loss: 0.5011 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m696/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0634 - loss: 0.5184\n",
      "Epoch 41: val_loss improved from 0.50106 to 0.49988, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0634 - loss: 0.5184 - val_accuracy: 0.0617 - val_loss: 0.4999 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m698/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0604 - loss: 0.5182\n",
      "Epoch 42: val_loss improved from 0.49988 to 0.49871, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0604 - loss: 0.5182 - val_accuracy: 0.0617 - val_loss: 0.4987 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m680/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0628 - loss: 0.5171\n",
      "Epoch 43: val_loss improved from 0.49871 to 0.49755, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0627 - loss: 0.5171 - val_accuracy: 0.0617 - val_loss: 0.4975 - learning_rate: 0.0010\n",
      "Epoch 44/80\n",
      "\u001b[1m691/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5136\n",
      "Epoch 44: val_loss improved from 0.49755 to 0.49639, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0619 - loss: 0.5136 - val_accuracy: 0.0617 - val_loss: 0.4964 - learning_rate: 0.0010\n",
      "Epoch 45/80\n",
      "\u001b[1m692/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0618 - loss: 0.5124\n",
      "Epoch 45: val_loss improved from 0.49639 to 0.49524, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0618 - loss: 0.5124 - val_accuracy: 0.0617 - val_loss: 0.4952 - learning_rate: 0.0010\n",
      "Epoch 46/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 0.5102\n",
      "Epoch 46: val_loss improved from 0.49524 to 0.49410, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 0.5103 - val_accuracy: 0.0617 - val_loss: 0.4941 - learning_rate: 0.0010\n",
      "Epoch 47/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5098\n",
      "Epoch 47: val_loss improved from 0.49410 to 0.49296, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0615 - loss: 0.5098 - val_accuracy: 0.0617 - val_loss: 0.4930 - learning_rate: 0.0010\n",
      "Epoch 48/80\n",
      "\u001b[1m682/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0620 - loss: 0.5070\n",
      "Epoch 48: val_loss improved from 0.49296 to 0.49183, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0620 - loss: 0.5071 - val_accuracy: 0.0617 - val_loss: 0.4918 - learning_rate: 0.0010\n",
      "Epoch 49/80\n",
      "\u001b[1m686/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0612 - loss: 0.5120\n",
      "Epoch 49: val_loss improved from 0.49183 to 0.49069, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0613 - loss: 0.5120 - val_accuracy: 0.0617 - val_loss: 0.4907 - learning_rate: 0.0010\n",
      "Epoch 50/80\n",
      "\u001b[1m692/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0618 - loss: 0.5063\n",
      "Epoch 50: val_loss improved from 0.49069 to 0.48955, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0618 - loss: 0.5063 - val_accuracy: 0.0617 - val_loss: 0.4895 - learning_rate: 0.0010\n",
      "Epoch 51/80\n",
      "\u001b[1m698/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0627 - loss: 0.5029\n",
      "Epoch 51: val_loss improved from 0.48955 to 0.48841, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0627 - loss: 0.5029 - val_accuracy: 0.0617 - val_loss: 0.4884 - learning_rate: 0.0010\n",
      "Epoch 52/80\n",
      "\u001b[1m682/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0601 - loss: 0.5051\n",
      "Epoch 52: val_loss improved from 0.48841 to 0.48728, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0602 - loss: 0.5051 - val_accuracy: 0.0617 - val_loss: 0.4873 - learning_rate: 0.0010\n",
      "Epoch 53/80\n",
      "\u001b[1m697/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0629 - loss: 0.5055\n",
      "Epoch 53: val_loss improved from 0.48728 to 0.48613, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0629 - loss: 0.5054 - val_accuracy: 0.0617 - val_loss: 0.4861 - learning_rate: 0.0010\n",
      "Epoch 54/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.4976\n",
      "Epoch 54: val_loss improved from 0.48613 to 0.48499, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.4976 - val_accuracy: 0.0617 - val_loss: 0.4850 - learning_rate: 0.0010\n",
      "Epoch 55/80\n",
      "\u001b[1m685/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0617 - loss: 0.5006\n",
      "Epoch 55: val_loss improved from 0.48499 to 0.48385, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0617 - loss: 0.5006 - val_accuracy: 0.0617 - val_loss: 0.4838 - learning_rate: 0.0010\n",
      "Epoch 56/80\n",
      "\u001b[1m696/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0630 - loss: 0.5027\n",
      "Epoch 56: val_loss improved from 0.48385 to 0.48271, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0630 - loss: 0.5027 - val_accuracy: 0.0617 - val_loss: 0.4827 - learning_rate: 0.0010\n",
      "Epoch 57/80\n",
      "\u001b[1m685/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0602 - loss: 0.4991\n",
      "Epoch 57: val_loss improved from 0.48271 to 0.48156, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0602 - loss: 0.4991 - val_accuracy: 0.0617 - val_loss: 0.4816 - learning_rate: 0.0010\n",
      "Epoch 58/80\n",
      "\u001b[1m695/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0636 - loss: 0.4967\n",
      "Epoch 58: val_loss improved from 0.48156 to 0.48040, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0635 - loss: 0.4967 - val_accuracy: 0.0617 - val_loss: 0.4804 - learning_rate: 0.0010\n",
      "Epoch 59/80\n",
      "\u001b[1m680/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.4956\n",
      "Epoch 59: val_loss improved from 0.48040 to 0.47924, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0624 - loss: 0.4955 - val_accuracy: 0.0617 - val_loss: 0.4792 - learning_rate: 0.0010\n",
      "Epoch 60/80\n",
      "\u001b[1m695/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0639 - loss: 0.4926\n",
      "Epoch 60: val_loss improved from 0.47924 to 0.47809, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0639 - loss: 0.4926 - val_accuracy: 0.0618 - val_loss: 0.4781 - learning_rate: 0.0010\n",
      "Epoch 61/80\n",
      "\u001b[1m683/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 0.4983\n",
      "Epoch 61: val_loss improved from 0.47809 to 0.47695, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 0.4981 - val_accuracy: 0.0618 - val_loss: 0.4769 - learning_rate: 0.0010\n",
      "Epoch 62/80\n",
      "\u001b[1m686/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0627 - loss: 0.4878\n",
      "Epoch 62: val_loss improved from 0.47695 to 0.47581, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0628 - loss: 0.4879 - val_accuracy: 0.0619 - val_loss: 0.4758 - learning_rate: 0.0010\n",
      "Epoch 63/80\n",
      "\u001b[1m695/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0638 - loss: 0.4908\n",
      "Epoch 63: val_loss improved from 0.47581 to 0.47465, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0638 - loss: 0.4908 - val_accuracy: 0.0619 - val_loss: 0.4747 - learning_rate: 0.0010\n",
      "Epoch 64/80\n",
      "\u001b[1m694/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0638 - loss: 0.4881\n",
      "Epoch 64: val_loss improved from 0.47465 to 0.47349, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0638 - loss: 0.4882 - val_accuracy: 0.0619 - val_loss: 0.4735 - learning_rate: 0.0010\n",
      "Epoch 65/80\n",
      "\u001b[1m692/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0642 - loss: 0.4885\n",
      "Epoch 65: val_loss improved from 0.47349 to 0.47232, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0642 - loss: 0.4885 - val_accuracy: 0.0619 - val_loss: 0.4723 - learning_rate: 0.0010\n",
      "Epoch 66/80\n",
      "\u001b[1m692/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0634 - loss: 0.4863\n",
      "Epoch 66: val_loss improved from 0.47232 to 0.47116, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0634 - loss: 0.4863 - val_accuracy: 0.0619 - val_loss: 0.4712 - learning_rate: 0.0010\n",
      "Epoch 67/80\n",
      "\u001b[1m689/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0636 - loss: 0.4852\n",
      "Epoch 67: val_loss improved from 0.47116 to 0.47000, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0636 - loss: 0.4852 - val_accuracy: 0.0620 - val_loss: 0.4700 - learning_rate: 0.0010\n",
      "Epoch 68/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0640 - loss: 0.4850\n",
      "Epoch 68: val_loss improved from 0.47000 to 0.46885, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0640 - loss: 0.4850 - val_accuracy: 0.0621 - val_loss: 0.4688 - learning_rate: 0.0010\n",
      "Epoch 69/80\n",
      "\u001b[1m684/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0639 - loss: 0.4811\n",
      "Epoch 69: val_loss improved from 0.46885 to 0.46769, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0640 - loss: 0.4811 - val_accuracy: 0.0622 - val_loss: 0.4677 - learning_rate: 0.0010\n",
      "Epoch 70/80\n",
      "\u001b[1m680/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0649 - loss: 0.4822\n",
      "Epoch 70: val_loss improved from 0.46769 to 0.46654, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0649 - loss: 0.4822 - val_accuracy: 0.0622 - val_loss: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 71/80\n",
      "\u001b[1m691/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0652 - loss: 0.4812\n",
      "Epoch 71: val_loss improved from 0.46654 to 0.46540, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0652 - loss: 0.4812 - val_accuracy: 0.0625 - val_loss: 0.4654 - learning_rate: 0.0010\n",
      "Epoch 72/80\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0646 - loss: 0.4780\n",
      "Epoch 72: val_loss improved from 0.46540 to 0.46427, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0646 - loss: 0.4780 - val_accuracy: 0.0629 - val_loss: 0.4643 - learning_rate: 0.0010\n",
      "Epoch 73/80\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0650 - loss: 0.4789\n",
      "Epoch 73: val_loss improved from 0.46427 to 0.46315, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0650 - loss: 0.4789 - val_accuracy: 0.0633 - val_loss: 0.4631 - learning_rate: 0.0010\n",
      "Epoch 74/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0659 - loss: 0.4800\n",
      "Epoch 74: val_loss improved from 0.46315 to 0.46204, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0659 - loss: 0.4799 - val_accuracy: 0.0642 - val_loss: 0.4620 - learning_rate: 0.0010\n",
      "Epoch 75/80\n",
      "\u001b[1m682/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0684 - loss: 0.4768\n",
      "Epoch 75: val_loss improved from 0.46204 to 0.46093, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0683 - loss: 0.4768 - val_accuracy: 0.0649 - val_loss: 0.4609 - learning_rate: 0.0010\n",
      "Epoch 76/80\n",
      "\u001b[1m692/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0675 - loss: 0.4721\n",
      "Epoch 76: val_loss improved from 0.46093 to 0.45985, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0675 - loss: 0.4721 - val_accuracy: 0.0657 - val_loss: 0.4599 - learning_rate: 0.0010\n",
      "Epoch 77/80\n",
      "\u001b[1m696/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0678 - loss: 0.4758\n",
      "Epoch 77: val_loss improved from 0.45985 to 0.45877, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0678 - loss: 0.4758 - val_accuracy: 0.0660 - val_loss: 0.4588 - learning_rate: 0.0010\n",
      "Epoch 78/80\n",
      "\u001b[1m700/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0684 - loss: 0.4716\n",
      "Epoch 78: val_loss improved from 0.45877 to 0.45771, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0684 - loss: 0.4716 - val_accuracy: 0.0667 - val_loss: 0.4577 - learning_rate: 0.0010\n",
      "Epoch 79/80\n",
      "\u001b[1m693/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0687 - loss: 0.4702\n",
      "Epoch 79: val_loss improved from 0.45771 to 0.45666, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0687 - loss: 0.4702 - val_accuracy: 0.0675 - val_loss: 0.4567 - learning_rate: 0.0010\n",
      "Epoch 80/80\n",
      "\u001b[1m690/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0699 - loss: 0.4665\n",
      "Epoch 80: val_loss improved from 0.45666 to 0.45564, saving model to best_model.keras\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0700 - loss: 0.4666 - val_accuracy: 0.0680 - val_loss: 0.4556 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss', \n",
    "#     factor=0.75, \n",
    "#     patience=3, \n",
    "#     min_lr=0.000001, \n",
    "#     verbose=1)\n",
    "\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     'best_model.keras',\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,\n",
    "#     mode='auto'\n",
    "# )\n",
    "\n",
    "# history = model.fit(x = X_train_array, y = Y_train, batch_size=128, epochs=70, verbose=1, validation_data=(X_test_array, Y_test)\n",
    "# ,shuffle=True,callbacks=[reduce_lr, checkpoint])\n",
    "\n",
    "# Learning rate reduction callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.75,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,  # 0.000001,\n",
    "    verbose=1,\n",
    "    min_delta=1e-4  # Minimum change to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_weights_only=False  # Save the entire model\n",
    ")\n",
    "\n",
    "# Training the model with proper input format\n",
    "history = model.fit(x = X_train_array, \n",
    "                    y = Y_train, \n",
    "                    batch_size=128, \n",
    "                    epochs=80, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_array, Y_test),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[reduce_lr, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"][5:])\n",
    "plt.plot(history.history[\"val_loss\"][5:])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>rating</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101 Dalmatians (1996)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20,000 Leagues Under the Sea (1954)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2001: A Space Odyssey (1968)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Abyss, The (1989)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id                          movie title  rating  user  movie\n",
       "0        1                101 Dalmatians (1996)     2.0     0      2\n",
       "1        1                  12 Angry Men (1957)     5.0     0      3\n",
       "2        1  20,000 Leagues Under the Sea (1954)     3.0     0      6\n",
       "3        1         2001: A Space Odyssey (1968)     4.0     0      7\n",
       "4        1                    Abyss, The (1989)     3.0     0     16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([180, 487, 177, ..., 431, 232, 138]),\n",
       " array([1152,  389,  302, ..., 1588,  399,  612])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 55, 87, 113, 313, 337, 389, 390, 399, 411, 432, 460, 498, 528, 580, 604, 612, 643, 666, 783, 996, 1005, 1032, 1102, 1132, 1157, 1190, 1208, 1251, 1260, 1284, 1302, 1342, 1523, 1558, 1615]\n"
     ]
    }
   ],
   "source": [
    "user_id = [777]\n",
    "encoded_user_id = user_enc.transform(user_id)\n",
    "\n",
    "seen_movies = list(refined_dataset[refined_dataset['user id'] == user_id[0]]['movie'])\n",
    "print(seen_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 0, 1663)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(refined_dataset['movie'].unique()), min(refined_dataset['movie']), max(refined_dataset['movie'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unseen_movies = [i for i in range(min(refined_dataset['movie']), max(refined_dataset['movie'])+1) if i not in seen_movies]\n",
    "print(unseen_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_movies) + len(seen_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1628)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = [np.asarray(list(encoded_user_id)*len(unseen_movies)), np.asarray(unseen_movies)]\n",
    "len(model_input), len(model_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsharma/.pyenv/versions/movie_recommend/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'keras_tensor_2']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings = model.predict(model_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1628, 9)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ratings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.92290986e-01 2.02559143e-01 8.80366017e-04 ... 5.32412028e-04\n",
      "  9.54189862e-04 8.27044714e-04]\n",
      " [8.01743090e-01 1.93393469e-01 7.77141540e-04 ... 5.28398552e-04\n",
      "  8.85953603e-04 7.94950931e-04]\n",
      " [8.96273136e-01 1.02115706e-01 2.22123970e-04 ... 1.81644311e-04\n",
      "  2.50720506e-04 2.60654895e-04]\n",
      " ...\n",
      " [8.56773436e-01 1.39539868e-01 5.11194288e-04 ... 4.23079793e-04\n",
      "  5.97230741e-04 6.05635752e-04]\n",
      " [8.60103488e-01 1.37243614e-01 3.97456781e-04 ... 2.90206983e-04\n",
      "  4.44153906e-04 4.23449004e-04]\n",
      " [8.19488943e-01 1.75113603e-01 8.44608061e-04 ... 5.83759684e-04\n",
      "  9.13085823e-04 8.78665189e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1553  840    2 ... 1285 1251 1365]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Two or Three Things I Know About Her (1966)',\n",
       "       'Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)',\n",
       "       '101 Dalmatians (1996)', ..., 'Scream 2 (1997)',\n",
       "       'Rock, The (1996)', 'Sound of Music, The (1965)'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = np.max(predicted_ratings, axis=1)\n",
    "predicted_ratings\n",
    "predicted_ratings.shape\n",
    "sorted_index = np.argsort(predicted_ratings)[::-1]\n",
    "print(sorted_index)\n",
    "recommended_movies = movie_enc.inverse_transform(sorted_index)\n",
    "recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two or Three Things I Know About Her (1966)',\n",
      " 'Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)',\n",
      " '101 Dalmatians (1996)',\n",
      " 'Bride of Frankenstein (1935)',\n",
      " 'Mallrats (1995)',\n",
      " 'Moonlight and Valentino (1995)',\n",
      " 'Full Monty, The (1997)',\n",
      " 'Jaws 2 (1978)',\n",
      " 'Diva (1981)',\n",
      " 'River Wild, The (1994)',\n",
      " 'That Darn Cat! (1965)',\n",
      " 'Of Love and Shadows (1994)',\n",
      " 'Mercury Rising (1998)',\n",
      " \"She's the One (1996)\",\n",
      " 'Innocents, The (1961)',\n",
      " 'Escape from L.A. (1996)',\n",
      " \"Miller's Crossing (1990)\",\n",
      " 'Big Squeeze, The (1996)',\n",
      " 'Feast of July (1995)',\n",
      " 'Judgment Night (1993)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "pprint(list(recommended_movies[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system(user_id, model, n_movies):\n",
    "\n",
    "  print(\"\")\n",
    "  print(\"Movie seen by the User:\")\n",
    "  pprint(list(refined_dataset[refined_dataset['user id'] == user_id]['movie title']))\n",
    "  print(\"\")\n",
    "\n",
    "  encoded_user_id = user_enc.transform([user_id])\n",
    "\n",
    "  seen_movies = list(refined_dataset[refined_dataset['user id'] == user_id]['movie'])\n",
    "  unseen_movies = [i for i in range(min(refined_dataset['movie']), max(refined_dataset['movie'])+1) if i not in seen_movies]\n",
    "  model_input = [np.asarray(list(encoded_user_id)*len(unseen_movies)), np.asarray(unseen_movies)]\n",
    "  predicted_ratings = model.predict(model_input)\n",
    "  predicted_ratings = np.max(predicted_ratings, axis=1)\n",
    "  sorted_index = np.argsort(predicted_ratings)[::-1]\n",
    "  recommended_movies = movie_enc.inverse_transform(sorted_index)\n",
    "  print(\"---------------------------------------------------------------------------------\")\n",
    "  print(\"Top \"+str(n_movies)+\" Movie recommendations for the User \"+str(user_id)+ \" are:\")\n",
    "  pprint(list(recommended_movies[:n_movies]))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie seen by the User:\n",
      "['101 Dalmatians (1996)',\n",
      " 'Adventures of Pinocchio, The (1996)',\n",
      " 'Beautiful Girls (1996)',\n",
      " 'Bed of Roses (1996)',\n",
      " 'Birdcage, The (1996)',\n",
      " 'Blue in the Face (1995)',\n",
      " \"Don't Be a Menace to South Central While Drinking Your Juice in the Hood \"\n",
      " '(1996)',\n",
      " 'Down Periscope (1996)',\n",
      " 'Dragonheart (1996)',\n",
      " 'Eraser (1996)',\n",
      " 'Evening Star, The (1996)',\n",
      " 'Fargo (1996)',\n",
      " 'Father of the Bride Part II (1995)',\n",
      " 'First Wives Club, The (1996)',\n",
      " 'Godfather, The (1972)',\n",
      " 'Happy Gilmore (1996)',\n",
      " 'Hercules (1997)',\n",
      " 'Hunchback of Notre Dame, The (1996)',\n",
      " 'If Lucy Fell (1996)',\n",
      " 'Independence Day (ID4) (1996)',\n",
      " 'James and the Giant Peach (1996)',\n",
      " 'Jerry Maguire (1996)',\n",
      " 'Kids in the Hall: Brain Candy (1996)',\n",
      " 'Leaving Las Vegas (1995)',\n",
      " 'Men in Black (1997)',\n",
      " 'Mighty Aphrodite (1995)',\n",
      " \"Mr. Holland's Opus (1995)\",\n",
      " 'Mulholland Falls (1996)',\n",
      " 'Muppet Treasure Island (1996)',\n",
      " 'Mystery Science Theater 3000: The Movie (1996)',\n",
      " 'Nutty Professor, The (1996)',\n",
      " 'Phantom, The (1996)',\n",
      " \"Preacher's Wife, The (1996)\",\n",
      " 'Ransom (1996)',\n",
      " 'Return of the Jedi (1983)',\n",
      " 'Rumble in the Bronx (1995)',\n",
      " 'Scream (1996)',\n",
      " 'Space Jam (1996)',\n",
      " 'Star Wars (1977)',\n",
      " 'Stupids, The (1996)',\n",
      " 'That Thing You Do! (1996)',\n",
      " 'Time to Kill, A (1996)',\n",
      " 'Tin Cup (1996)',\n",
      " 'Toy Story (1995)',\n",
      " 'Truth About Cats & Dogs, The (1996)',\n",
      " 'Twelve Monkeys (1995)',\n",
      " 'Twister (1996)',\n",
      " 'Willy Wonka and the Chocolate Factory (1971)']\n",
      "\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step\n",
      "---------------------------------------------------------------------------------\n",
      "Top 10 Movie recommendations for the User 45 are:\n",
      "['Turning, The (1992)',\n",
      " 'Lashou shentan (1992)',\n",
      " \"Breakfast at Tiffany's (1961)\",\n",
      " 'Magic Hour, The (1998)',\n",
      " 'Moll Flanders (1996)',\n",
      " 'Full Speed (1996)',\n",
      " 'Designated Mourner, The (1997)',\n",
      " \"Jason's Lyric (1994)\",\n",
      " 'Mighty Aphrodite (1995)',\n",
      " 'Richard III (1995)']\n"
     ]
    }
   ],
   "source": [
    "user_id= 45\n",
    "n_movies = 10\n",
    "recommender_system(user_id,model,n_movies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
